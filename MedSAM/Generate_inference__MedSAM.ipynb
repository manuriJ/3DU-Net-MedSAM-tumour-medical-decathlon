{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrfJEXtAZYuH",
        "outputId": "aaa57250-88a6-488e-994c-f640650a47cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.10.14\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "\n",
        "print(python_version())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from skimage import transform\n",
        "import warnings\n",
        "import nibabel as nib\n",
        "from tqdm import tqdm\n",
        "from segment_anything import sam_model_registry\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "NfFH7-hdZa1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ5UtBEW--kG"
      },
      "outputs": [],
      "source": [
        "dataset_path=\"/home/manuri/data/Task01_BrainTumour_org/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ-0XX6AZYuK"
      },
      "outputs": [],
      "source": [
        "json_path=\"/home/manuri/data/Task01_BrainTumour/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR4NqRTcwLUu"
      },
      "outputs": [],
      "source": [
        "# Load the image files from the original source folder\n",
        "json_filename = os.path.join(json_path, \"dataset.json\")\n",
        "\n",
        "try:\n",
        "    with open(json_filename, \"r\") as fp:\n",
        "        experiment_data = json.load(fp)\n",
        "except IOError as e:\n",
        "    print(\"File {} doesn't exist. It should be part of the \"\n",
        "          \"Decathlon directory\".format(json_filename))\n",
        "\n",
        "output_channels = experiment_data[\"labels\"]\n",
        "input_channels = experiment_data[\"modality\"]\n",
        "description = experiment_data[\"description\"]\n",
        "name = experiment_data[\"name\"]\n",
        "release = experiment_data[\"release\"]\n",
        "license = experiment_data[\"licence\"]\n",
        "reference = experiment_data[\"reference\"]\n",
        "tensorImageSize = experiment_data[\"tensorImageSize\"]\n",
        "numFiles = experiment_data[\"numTraining\"]\n",
        "numFiles_Test = experiment_data[\"numTest\"]\n",
        "\n",
        "filenames = {}\n",
        "img = []\n",
        "label = []\n",
        "for idx in range(numFiles_Test):\n",
        "    img.append(os.path.join(dataset_path,experiment_data[\"test\"][idx][\"image\"]))\n",
        "    label.append(os.path.join(dataset_path,experiment_data[\"test\"][idx][\"label\"]))\n",
        "\n",
        "filenames['images'] = img\n",
        "filenames['label'] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gfAnz5H2KKy",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8IBxqVVZYuL",
        "outputId": "5e29b3b8-a856-476a-a53e-5baa4cd9d082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(filenames['images'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3PivloWZYuM",
        "outputId": "35607915-8774-438a-8b8d-0cc3e35ae8e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M1-F8GM81nn",
        "scrolled": true,
        "outputId": "7f654f88-32ce-40af-fbdd-ce432096f354"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 73/73 [1:24:46<00:00, 69.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metrics:\n",
            "overall_dice: 0.7407\n",
            "dice_edema: 0.5306\n",
            "precision_edema: 0.3790\n",
            "recall_edema: 0.9508\n",
            "f1_edema: 0.5306\n",
            "dice_non-enhancing tumor: 0.0000\n",
            "precision_non-enhancing tumor: 0.0000\n",
            "recall_non-enhancing tumor: 0.0000\n",
            "f1_non-enhancing tumor: 0.0000\n",
            "dice_enhancing tumour: 0.0000\n",
            "precision_enhancing tumour: 0.0000\n",
            "recall_enhancing tumour: 0.0000\n",
            "f1_enhancing tumour: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load, preprocess data and generate the segementation masks\n",
        "\n",
        "def load_nifti(file_path):\n",
        "    return nib.load(file_path).get_fdata()\n",
        "\n",
        "def preprocess_slice(slice_data, target_size=(1024, 1024)):\n",
        "    \"\"\"\n",
        "    Preprocess a single slice of MRI data.\n",
        "\n",
        "    Args:\n",
        "    slice_data (np.ndarray): Input 2D slice of MRI data\n",
        "    target_size (tuple): Desired output size (height, width)\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Preprocessed slice with shape (*target_size, 3)\n",
        "    \"\"\"\n",
        "    # Ensure the input is 2D\n",
        "    if slice_data.ndim != 2:\n",
        "        raise ValueError(f\"Expected 2D input, got shape {slice_data.shape}\")\n",
        "\n",
        "    # Handle NaN values\n",
        "    if np.isnan(slice_data).any():\n",
        "        #warnings.warn(\"NaN values found in input slice. Replacing with zeros.\")\n",
        "        slice_data = np.nan_to_num(slice_data, nan=0.0)\n",
        "\n",
        "    # Clip extreme values (e.g., outliers)\n",
        "    p1, p99 = np.percentile(slice_data, (1, 99))\n",
        "    slice_data = np.clip(slice_data, p1, p99)\n",
        "\n",
        "    # Normalize to [0, 1] range\n",
        "    slice_min, slice_max = slice_data.min(), slice_data.max()\n",
        "    if slice_min == slice_max:\n",
        "        #warnings.warn(\"Constant intensity slice encountered. Returning zeros.\")\n",
        "        return np.zeros((*target_size, 3), dtype=np.float32)\n",
        "\n",
        "    slice_data = (slice_data - slice_min) / (slice_max - slice_min)\n",
        "\n",
        "    # Resize the slice\n",
        "    if slice_data.shape != target_size:\n",
        "        slice_data = transform.resize(\n",
        "            slice_data,\n",
        "            target_size,\n",
        "            order=3,  # cubic spline interpolation\n",
        "            mode='constant',\n",
        "            anti_aliasing=True,\n",
        "            preserve_range=True\n",
        "        )\n",
        "\n",
        "    # Ensure the output is in [0, 1] range after resize\n",
        "    slice_data = np.clip(slice_data, 0, 1)\n",
        "\n",
        "    # Convert to RGB-like format\n",
        "    slice_data_rgb = np.stack([slice_data] * 3, axis=-1)\n",
        "\n",
        "    return slice_data_rgb.astype(np.float32)\n",
        "\n",
        "def evaluate_slice(model, image_slice, mask_slice, device):\n",
        "    H, W = image_slice.shape\n",
        "    image_slice = preprocess_slice(image_slice)  # Now uses the improved function\n",
        "    image_tensor = torch.tensor(image_slice).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_embedding = model.image_encoder(image_tensor)\n",
        "\n",
        "    box = get_bounding_box(mask_slice)\n",
        "    box_1024 = np.array(box) / np.array([W, H, W, H]) * 1024\n",
        "    box_1024 = box_1024[None, :]\n",
        "\n",
        "    pred_mask = medsam_inference(model, image_embedding, box_1024, H, W)\n",
        "    pred_mask = transform.resize(pred_mask, (H, W), order=0, preserve_range=True, anti_aliasing=False)\n",
        "\n",
        "    return pred_mask.astype(np.uint8)\n",
        "\n",
        "def get_bounding_box(mask):\n",
        "    # Get bounding box for the tumor region (any non-background label)\n",
        "    rows = np.any(mask > 0, axis=1)\n",
        "    cols = np.any(mask > 0, axis=0)\n",
        "\n",
        "    if np.sum(rows) == 0 or np.sum(cols) == 0:\n",
        "        # If there's no tumor in this slice, return a small central box\n",
        "        h, w = mask.shape\n",
        "        center_h, center_w = h // 2, w // 2\n",
        "        box_size = 10  # Small box size\n",
        "        return [center_w - box_size // 2, center_h - box_size // 2,\n",
        "                center_w + box_size // 2, center_h + box_size // 2]\n",
        "\n",
        "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "\n",
        "    # Add a small padding to the bounding box\n",
        "    padding = 10\n",
        "    rmin = max(0, rmin - padding)\n",
        "    rmax = min(mask.shape[0] - 1, rmax + padding)\n",
        "    cmin = max(0, cmin - padding)\n",
        "    cmax = min(mask.shape[1] - 1, cmax + padding)\n",
        "\n",
        "    return [cmin, rmin, cmax, rmax]\n",
        "\n",
        "def evaluate_volume(model, image_volume, mask_volume, device):\n",
        "    predictions = []\n",
        "    for i in range(image_volume.shape[2]):  # Iterate through slices\n",
        "        image_slice = image_volume[:,:,i,3] if image_volume.ndim == 4 else image_volume[:,:,i]\n",
        "        mask_slice = mask_volume[:,:,i]\n",
        "\n",
        "        pred_slice = evaluate_slice(model, image_slice, mask_slice, device)\n",
        "        predictions.append(pred_slice)\n",
        "\n",
        "    return np.stack(predictions, axis=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def medsam_inference(medsam_model, img_embed, box_1024, H, W):\n",
        "    box_torch = torch.as_tensor(box_1024, dtype=torch.float, device=img_embed.device)\n",
        "    if len(box_torch.shape) == 1:  # (4,)\n",
        "        box_torch = box_torch.unsqueeze(0).unsqueeze(0)  # (1, 1, 4)\n",
        "    elif len(box_torch.shape) == 2:  # (B, 4) or (1, 4)\n",
        "        box_torch = box_torch.unsqueeze(1)  # (B, 1, 4) or (1, 1, 4)\n",
        "\n",
        "    #print(\"box_torch shape:\", box_torch.shape)\n",
        "\n",
        "    sparse_embeddings, dense_embeddings = medsam_model.prompt_encoder(\n",
        "        points=None,\n",
        "        boxes=box_torch,\n",
        "        masks=None,\n",
        "    )\n",
        "    low_res_logits, _ = medsam_model.mask_decoder(\n",
        "        image_embeddings=img_embed,\n",
        "        image_pe=medsam_model.prompt_encoder.get_dense_pe(),\n",
        "        sparse_prompt_embeddings=sparse_embeddings,\n",
        "        dense_prompt_embeddings=dense_embeddings,\n",
        "        multimask_output=False,\n",
        "    )\n",
        "\n",
        "    low_res_pred = torch.sigmoid(low_res_logits)\n",
        "\n",
        "    low_res_pred = F.interpolate(\n",
        "        low_res_pred,\n",
        "        size=(H, W),\n",
        "        mode=\"bilinear\",\n",
        "        align_corners=False,\n",
        "    )\n",
        "    medsam_seg = (low_res_pred > 0.5).squeeze().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "    if medsam_seg.ndim > 2:\n",
        "        medsam_seg = medsam_seg[0]\n",
        "\n",
        "    return medsam_seg\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-7):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
        "\n",
        "def hausdorff_distance(y_true, y_pred):\n",
        "    if np.sum(y_true) == 0 and np.sum(y_pred) == 0:\n",
        "        return 0.0\n",
        "    elif np.sum(y_true) == 0 or np.sum(y_pred) == 0:\n",
        "        return np.inf\n",
        "    return max(directed_hausdorff(y_true, y_pred)[0], directed_hausdorff(y_pred, y_true)[0])\n",
        "\n",
        "def calculate_metrics(true_mask, pred_mask):\n",
        "    metrics = {}\n",
        "    class_names = {0: \"background\", 1: \"edema\", 2: \"non-enhancing tumor\", 3: \"enhancing tumour\"}\n",
        "\n",
        "    # Overall metrics\n",
        "    true_foreground = (true_mask > 0).astype(int)\n",
        "    pred_foreground = (pred_mask > 0).astype(int)\n",
        "\n",
        "    metrics['overall_dice'] = dice_coefficient(true_foreground, pred_foreground)\n",
        "    #metrics['overall_hausdorff'] = hausdorff_distance(true_foreground, pred_foreground)\n",
        "\n",
        "    # Per-class metrics\n",
        "    for class_id in range(1, 4):  # Skip background class\n",
        "        true_class = (true_mask == class_id).astype(int)\n",
        "        pred_class = (pred_mask == class_id).astype(int)\n",
        "\n",
        "        if np.sum(true_class) == 0 and np.sum(pred_class) == 0:\n",
        "            # Both true and predicted masks are empty for this class\n",
        "            metrics[f'dice_{class_names[class_id]}'] = 1.0\n",
        "            metrics[f'precision_{class_names[class_id]}'] = 1.0\n",
        "            metrics[f'recall_{class_names[class_id]}'] = 1.0\n",
        "            metrics[f'f1_{class_names[class_id]}'] = 1.0\n",
        "            #metrics[f'hausdorff_{class_names[class_id]}'] = 0.0\n",
        "        elif np.sum(true_class) == 0 or np.sum(pred_class) == 0:\n",
        "            # One of the masks is empty, the other is not\n",
        "            metrics[f'dice_{class_names[class_id]}'] = 0.0\n",
        "            metrics[f'precision_{class_names[class_id]}'] = 0.0\n",
        "            metrics[f'recall_{class_names[class_id]}'] = 0.0\n",
        "            metrics[f'f1_{class_names[class_id]}'] = 0.0\n",
        "            #metrics[f'hausdorff_{class_names[class_id]}'] = np.inf\n",
        "        else:\n",
        "            # Both masks have some positive pixels\n",
        "            metrics[f'dice_{class_names[class_id]}'] = dice_coefficient(true_class, pred_class)\n",
        "            metrics[f'precision_{class_names[class_id]}'] = precision_score(true_class.flatten(), pred_class.flatten())\n",
        "            metrics[f'recall_{class_names[class_id]}'] = recall_score(true_class.flatten(), pred_class.flatten())\n",
        "            metrics[f'f1_{class_names[class_id]}'] = f1_score(true_class.flatten(), pred_class.flatten())\n",
        "            #metrics[f'hausdorff_{class_names[class_id]}'] = hausdorff_distance(true_class, pred_class)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_results(image, ground_truth, prediction, slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Plot original image\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title(f\"Original Image (Slice {slice_index})\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Plot ground truth mask\n",
        "    axes[1].imshow(ground_truth, cmap='nipy_spectral')\n",
        "    axes[1].set_title(f\"Ground Truth Mask (Slice {slice_index})\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Plot predicted mask\n",
        "    axes[2].imshow(prediction, cmap='nipy_spectral')\n",
        "    axes[2].set_title(f\"Predicted Mask (Slice {slice_index})\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load the pretrained model\n",
        "MedSAM_CKPT_PATH = \"medsam_vit_b.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH).to(device)\n",
        "model.eval()\n",
        "\n",
        "image_files = filenames['images']\n",
        "mask_files = filenames['label']\n",
        "\n",
        "all_metrics = []\n",
        "\n",
        "for img_file, mask_file in tqdm(zip(image_files, mask_files), total=len(image_files)):\n",
        "    image_volume = load_nifti(img_file)\n",
        "    mask_volume = load_nifti(mask_file)\n",
        "\n",
        "    pred_volume = evaluate_volume(model, image_volume, mask_volume, device)\n",
        "    metrics = calculate_metrics(mask_volume, pred_volume)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # random_plot_done = False\n",
        "\n",
        "    # #Randomly select one volume for plotting\n",
        "    # if not random_plot_done and random.random() < 0.2:  # 20% chance to plot for each volume\n",
        "    #     random_slice = random.randint(0, image_volume.shape[2] - 1)\n",
        "    #     plot_results(\n",
        "    #         image_volume[:, :, random_slice, 1] if image_volume.ndim == 4 else image_volume[:, :, random_slice],\n",
        "    #         mask_volume[:, :, random_slice],\n",
        "    #         pred_volume[:, :, random_slice],\n",
        "    #         random_slice\n",
        "    #     )\n",
        "    #     random_plot_done = True\n",
        "\n",
        "# Aggregate and print results\n",
        "average_metrics = {metric: np.mean([m[metric] for m in all_metrics]) for metric in all_metrics[0]}\n",
        "print(\"Average Metrics:\")\n",
        "for metric, value in average_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTYtK8eBZYuO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "medsam",
      "language": "python",
      "name": "medsam"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}